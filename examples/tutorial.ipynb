{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labtech Tutorial\n",
    "\n",
    "The following tutorial presents a complete example of using labtech to\n",
    "easily add parallelism and caching to machine learning experiments.\n",
    "\n",
    "You can also run this tutorial as an [interactive\n",
    "notebook](https://mybinder.org/v2/gh/ben-denham/labtech/main?filepath=examples/tutorial.ipynb).\n",
    "\n",
    "Before we begin, let’s install `labtech` along with some other\n",
    "dependencies we will use in this tutorial:"
   ],
   "id": "7f85f5d2-2513-462d-8e94-b12972086b3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install labtech mlflow scikit-learn"
   ],
   "id": "36f333bd-a4b0-455a-8276-7e683c60bb1c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s also clear any caches that were created by previous runs of this\n",
    "tutorial:"
   ],
   "id": "9dc87115-7b08-4257-80b8-dd5d85e66987"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf storage/tutorial/\n",
    "!mkdir -p storage/tutorial/"
   ],
   "id": "206fe531-1f2c-4e4c-ba02-8597694ade96"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a single experiment as a labtech task\n",
    "\n",
    "To get started, we’ll take the following simple machine learning\n",
    "experiment code and convert it to be run with labtech."
   ],
   "id": "c7a4e18f-259a-40d7-9d70-6d5f0f3fabd5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "digits_X, digits_y = datasets.load_digits(return_X_y=True)\n",
    "digits_X = StandardScaler().fit_transform(digits_X)\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=5,\n",
    "    random_state=42,\n",
    ")\n",
    "clf.fit(digits_X, digits_y)\n",
    "prob_y = clf.predict_proba(digits_X)\n",
    "\n",
    "print(f'{log_loss(digits_y, prob_y) = :.3}')"
   ],
   "id": "d07e5069-9d1a-4a82-bb27-92d47e7c01a7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this tutorial, we will use labtech to improve and extend this\n",
    "experiment, which currently:\n",
    "\n",
    "1.  Loads and scales the `digits` dataset.\n",
    "    -   This is a benchmark dataset where the goal is to train a\n",
    "        classifier that can correctly assign a number between 0 and 9 to\n",
    "        the image of a hand-written digit.\n",
    "    -   We will want to extend our experimentation to also include other\n",
    "        datasets.\n",
    "2.  Trains a random forest classifier on the digits dataset.\n",
    "    -   The classifier is configured with `n_estimators=5` (i.e. a\n",
    "        forest of 5 trees) and a fixed `random_state` (to ensure we get\n",
    "        the same result every time we run the code).\n",
    "    -   We will want to extend our experimentation to test other\n",
    "        `n_estimators` values and classifiers other than a random\n",
    "        forest.\n",
    "3.  Evaluates the classifier by calculating the logistic loss of\n",
    "    probabilities predicted by the classifier for the dataset.\n",
    "    -   Standard evaluation practice would be to calculate loss for a\n",
    "        separate test dataset, but we will use a single dataset for both\n",
    "        training and testing to simplify this tutorial.\n",
    "\n",
    "Let’s set up this same experiment to be run with labtech, providing us\n",
    "with a foundation that we can extend throughout this tutorial.\n",
    "\n",
    "First, we’ll define a labtech *task type* that will load the dataset,\n",
    "train the classifier, and return the probabilities predicted for the\n",
    "dataset. Defining a task type for our experiment is as simple as\n",
    "defining a class decorated with `@labtech.task` that defines a `run()`\n",
    "method that performs the experiment and returns its result (the\n",
    "predicted probabilities):"
   ],
   "id": "af3ba98d-f142-473d-b65e-dd29af36a27a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labtech\n",
    "\n",
    "@labtech.task\n",
    "class ClassifierExperiment:\n",
    "\n",
    "    def run(self):\n",
    "        digits_X, digits_y = datasets.load_digits(return_X_y=True)\n",
    "        digits_X = StandardScaler().fit_transform(digits_X)\n",
    "\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=5,\n",
    "            random_state=42,\n",
    "        )\n",
    "        clf.fit(digits_X, digits_y)\n",
    "        prob_y = clf.predict_proba(digits_X)\n",
    "        return prob_y"
   ],
   "id": "0a7f0536-2f35-4895-b98d-2ff4e30662b8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a labtech *lab* that can be used to execute the\n",
    "experiment. We’ll configure the lab to cache results in a folder called\n",
    "`storage/tutorial/classification_lab_1` and to display notebook-friendly\n",
    "progress bars:"
   ],
   "id": "b8014a8e-88b0-40e6-ac1b-5ad36cfa0950"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = labtech.Lab(storage='storage/tutorial/classification_lab_1')"
   ],
   "id": "f8f35352-4618-4015-b857-0913be1e2766"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a task instance of `ClassifierExperiment` and call\n",
    "`lab.run_task()` to run it. The output will be the predicted\n",
    "probabilities returned by the task’s `run()` method, so we can calculate\n",
    "the loss from them as before:"
   ],
   "id": "75359126-ad0c-466d-ae4e-8d8e2267cd1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_experiment = ClassifierExperiment()\n",
    "prob_y = lab.run_task(classifier_experiment)\n",
    "print(f'{log_loss(digits_y, prob_y) = :.3}')"
   ],
   "id": "b7df72d4-c047-4abe-a4a1-17ba7f94b7dd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An immediate benefit of running an experiment this way with labtech is\n",
    "that **the result will be cached to disk for future use**. Any future\n",
    "calls to run the same experiment (even after restarting Python) will\n",
    "load the result from the cache:"
   ],
   "id": "a512a4ec-7c7e-4546-b1ab-f01a84173211"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y = lab.run_task(classifier_experiment)\n",
    "print(f'{log_loss(digits_y, prob_y) = :.3}')"
   ],
   "id": "4fd9cb0f-d2f8-4e8b-ada6-cc9b81593483"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the task to return the prediction probabilities instead of just\n",
    "the loss metric gives us flexibility to change the evaluation in the\n",
    "future (e.g. from `log_loss` to another metric) while still being able\n",
    "to re-use the same cached result.\n",
    "\n",
    "We can also ask our lab to return `task` objects for all previously\n",
    "cached results for a given task type by calling `lab.cached_tasks()`. A\n",
    "given task could then be passed to `lab.run_task()` to load it’s result\n",
    "(or we could pass a list of tasks to `lab.run_tasks()`, as we will see\n",
    "in the next section of this tutorial)."
   ],
   "id": "9513f10f-98d6-41f5-8aed-d23179363ad4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.cached_tasks([\n",
    "    ClassifierExperiment,\n",
    "])"
   ],
   "id": "2dc3c051-3a18-428c-8dab-bea252ad08ea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is very important that you clear any cached results whenever you\n",
    "make a change that will impact the behaviour of a task** - otherwise\n",
    "your cached results may no longer reflect the actual result of the\n",
    "current code.\n",
    "\n",
    "You can clear the cached results for a list of tasks with\n",
    "`lab.uncache_tasks()`:"
   ],
   "id": "6ceb6276-a76a-4e2f-9b1b-6839ebea412d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.uncache_tasks([\n",
    "    classifier_experiment,\n",
    "])"
   ],
   "id": "64ef7c33-27fa-4fc9-8aaf-d67c46dbb51f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterising tasks, and running many tasks in parallel\n",
    "\n",
    "Let’s extend our experimentation to compare the results for classifiers\n",
    "configured with different `n_estimators` values.\n",
    "\n",
    "To do so, we’ll add an `n_estimators` parameter to our\n",
    "`ClassifierExperiment` task type and reference it within the `run()`\n",
    "method as `self.n_estimators`. Task parameters are declared in exactly\n",
    "the same way as\n",
    "[dataclass](https://docs.python.org/3/library/dataclasses.html) fields:"
   ],
   "id": "ac7000c9-37af-40cd-ae70-d2767e4c7225"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labtech\n",
    "\n",
    "@labtech.task\n",
    "class ClassifierExperiment:\n",
    "    n_estimators: int\n",
    "\n",
    "    def run(self):\n",
    "        digits_X, digits_y = datasets.load_digits(return_X_y=True)\n",
    "        digits_X = StandardScaler().fit_transform(digits_X)\n",
    "\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=self.n_estimators,\n",
    "            random_state=42,\n",
    "        )\n",
    "        clf.fit(digits_X, digits_y)\n",
    "        prob_y = clf.predict_proba(digits_X)\n",
    "        return prob_y"
   ],
   "id": "f68b18ce-3eb2-4640-b2f8-33a10f7d0ce8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll use a list comprehension to construct a list of\n",
    "`ClassifierExperiment` tasks with different `n_estimators` values:"
   ],
   "id": "50a5e979-05b4-4331-9061-ae7e450e99be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_experiments = [\n",
    "    ClassifierExperiment(\n",
    "        n_estimators=n_estimators,\n",
    "    )\n",
    "    for n_estimators in range(1, 11)\n",
    "]"
   ],
   "id": "48adc8b4-1988-4814-b148-2122861a9a0b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a list of tasks with `lab.run_tasks()`, which has the added\n",
    "benefit of leveraging Python’s multiprocessing capabilities to **run the\n",
    "tasks in parallel** - running as many tasks simultaneously as possible\n",
    "with the CPU of the machine running the tasks. Also, because we’ve\n",
    "changed the definition of our `ClassifierExperiment` class, we’ll keep\n",
    "caches for the new definition separate by constructing a new lab that\n",
    "uses a different storage directory:"
   ],
   "id": "4d4202f2-d544-4023-8451-f4963b2b286c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = labtech.Lab(storage='storage/tutorial/classification_lab_2')\n",
    "results = lab.run_tasks(classifier_experiments)"
   ],
   "id": "fed80dc4-9ada-4b1e-b38d-99616652a5e1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lab.run_tasks()` returns a dictionary mapping each input task to the\n",
    "result it returned, which we can loop over to print loss metrics for\n",
    "each experiment:"
   ],
   "id": "3356fd33-925f-4472-9270-0908483debdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment, prob_y in results.items():\n",
    "    print(f'{experiment}: {log_loss(digits_y, prob_y) = :.3}')"
   ],
   "id": "45b999e7-dd20-4406-958b-a94ce2abbe5a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximising concurrency and caching with dependent tasks\n",
    "\n",
    "Labtech’s true power lies in its ability to manage complex networks of\n",
    "dependent tasks - automatically running as many tasks as possible in\n",
    "parallel (even different types of tasks) and re-using cached results\n",
    "wherever possible.\n",
    "\n",
    "To demonstrate this, let’s extend our experimentation with a new\n",
    "post-processing step that will take the probabilities returned by one of\n",
    "our previous `ClassifierExperiment` tasks and assign a probability of\n",
    "`1` to the most likely class for each record (and conversely assign a\n",
    "probability of `0` to all other classes).\n",
    "\n",
    "To achieve this, we will define a new `MinMaxProbabilityExperiment` task\n",
    "type that accepts a `ClassifierExperiment` as a parameter. Labtech will\n",
    "consider any task in a parameter to be a *dependency* of the task.\n",
    "Dependency tasks will be run before any of their dependent tasks,\n",
    "allowing us to access the result from the `.result` attribute of the\n",
    "task parameter (i.e. `self.classifier_experiment.result`):"
   ],
   "id": "f1df4399-d700-4663-b3e1-b5e37face5a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "@labtech.task\n",
    "class MinMaxProbabilityExperiment:\n",
    "    classifier_experiment: ClassifierExperiment\n",
    "\n",
    "    def run(self):\n",
    "        prob_y = self.classifier_experiment.result\n",
    "        # Replace the maximum probability in each row with 1,\n",
    "        # and replace all other probabilities with 0.\n",
    "        min_max_prob_y = np.zeros(prob_y.shape)\n",
    "        min_max_prob_y[np.arange(len(prob_y)), prob_y.argmax(axis=1)] = 1\n",
    "        return min_max_prob_y"
   ],
   "id": "eed17aa6-8d5d-432e-9ee9-4d4b0c10c2e1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then construct and run a list of `MinMaxProbabilityExperiment`\n",
    "tasks that depend on our previous `ClassifierExperiment` tasks in\n",
    "`classifier_experiments`. Labtech will ensure each of the\n",
    "`classifier_experiments` has been run before it’s dependent\n",
    "`MinMaxProbabilityExperiment` is run, re-using results depended on by\n",
    "multiple tasks and loading previously cached results wherever possible:"
   ],
   "id": "dd029cc9-e84c-4edf-9af7-3089e5ec1f77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_prob_experiments = [\n",
    "    MinMaxProbabilityExperiment(\n",
    "        classifier_experiment=classifier_experiment,\n",
    "    )\n",
    "    for classifier_experiment in classifier_experiments\n",
    "]\n",
    "\n",
    "results = lab.run_tasks(min_max_prob_experiments)\n",
    "for experiment, prob_y in results.items():\n",
    "    print(f'{experiment}: {log_loss(digits_y, prob_y) = :.3}')"
   ],
   "id": "ee6fa836-4e80-4054-95ed-43eccb3cc4e0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By simply specifying task dependencies, you can construct any task\n",
    "structure that can be expressed as a [directed acyclic graph (or\n",
    "DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph) and let\n",
    "labtech handle running tasks concurrently, sharing results between\n",
    "dependent tasks, and using caches wherever possible.\n",
    "\n",
    "### Parameterising tasks with complex objects\n",
    "\n",
    "Now let’s extend our experimentation to compare different classifier\n",
    "models. We’d like to make the classifier itself a parameter to the task,\n",
    "but task parameters can only be [json-serializable\n",
    "values](https://ben-denham.github.io/labtech/core/#labtech.task) or\n",
    "dependency tasks. Therefore, we will use dependency tasks to construct\n",
    "and return classifier objects to our experiment tasks. We achieve this\n",
    "in the following code by:\n",
    "\n",
    "1.  Defining `RFClassifierTask` and `LRClassifierTask` task types.\n",
    "    -   `RFClassifierTask` returns a random forest classifier\n",
    "        parameterised by an `n_estimators` value.\n",
    "    -   `LRClassifierTask` returns a logistic regression classifier.\n",
    "    -   Because constructing a classifier object is inexpensive, we\n",
    "        don’t need to cache them, so we set `cache=None` in the\n",
    "        `@labtech.task` decorator for these task types.\n",
    "    -   For type hinting purposes, we will identify these task types\n",
    "        with the `ClassifierTask`\n",
    "        [Protocol](https://docs.python.org/3/library/typing.html#typing.Protocol),\n",
    "        which will match any task type that returns an sklearn\n",
    "        classifier.\n",
    "2.  Redefining `ClassifierExperiment` to be parameterised by a\n",
    "    `ClassifierTask`.\n",
    "    -   The classifier object to be trained and applied is retrieved\n",
    "        from the `ClassifierTask` result with\n",
    "        `self.classifier_task.result`.\n",
    "    -   Because one `ClassifierTask` result may be shared by many\n",
    "        `ClassifierExperiment` tasks, the `run()` method first creates\n",
    "        its own copy of the classifier with `clone()`."
   ],
   "id": "04e2da36-c38d-4e8b-86af-11ad4fa8aa10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol\n",
    "\n",
    "from sklearn.base import clone, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class ClassifierTask(Protocol):\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        pass\n",
    "\n",
    "\n",
    "@labtech.task(cache=None)\n",
    "class RFClassifierTask:\n",
    "    n_estimators: int\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=self.n_estimators,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "\n",
    "@labtech.task(cache=None)\n",
    "class LRClassifierTask:\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        return LogisticRegression(\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "\n",
    "@labtech.task\n",
    "class ClassifierExperiment:\n",
    "    classifier_task: ClassifierTask\n",
    "\n",
    "    def run(self):\n",
    "        digits_X, digits_y = datasets.load_digits(return_X_y=True)\n",
    "        digits_X = StandardScaler().fit_transform(digits_X)\n",
    "\n",
    "        clf = clone(self.classifier_task.result)\n",
    "        clf.fit(digits_X, digits_y)\n",
    "        prob_y = clf.predict_proba(digits_X)\n",
    "        return prob_y"
   ],
   "id": "7bfbb941-53bf-4db5-98de-ffb04dac8b6f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate and run a set of `RFClassifierTask` tasks for\n",
    "various `n_estimators` values, and construct a `ClassifierExperiment`\n",
    "for each of these `RFClassifierTask` tasks as well as an\n",
    "`LRClassifierTask` task:"
   ],
   "id": "ef917198-3cb9-4a25-a712-f9293f4947e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_tasks = [\n",
    "    RFClassifierTask(\n",
    "        n_estimators=n_estimators,\n",
    "    )\n",
    "    for n_estimators in range(1, 11)\n",
    "]\n",
    "classifier_experiments = [\n",
    "    ClassifierExperiment(\n",
    "        classifier_task=classifier_task,\n",
    "    )\n",
    "    for classifier_task in [\n",
    "        LRClassifierTask(),\n",
    "        *rf_classifier_tasks,\n",
    "    ]\n",
    "]\n",
    "\n",
    "lab = labtech.Lab(storage='storage/tutorial/classification_lab_3')\n",
    "\n",
    "results = lab.run_tasks(classifier_experiments)\n",
    "for experiment, prob_y in results.items():\n",
    "    print(f'{experiment}: {log_loss(digits_y, prob_y) = :.3}')"
   ],
   "id": "a9e67657-f54c-4724-823b-be5462d00b76"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing large objects as context\n",
    "\n",
    "Sometimes we want to pass large, unchanging objects to our tasks, but\n",
    "don’t want to be forced to load them in a dependent task. For example,\n",
    "it would be convenient to load a collection of datasets (on which to run\n",
    "our experiments) outside of any task, allowing us to inspect these\n",
    "datasets before and after the tasks have been run:"
   ],
   "id": "89b6bf91-d900-4b1c-8da1-2ef4941fd4e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "iris_X = StandardScaler().fit_transform(iris_X)\n",
    "\n",
    "DATASETS = {\n",
    "    'digits': {'X': digits_X, 'y': digits_y},\n",
    "    'iris': {'X': iris_X, 'y': iris_y},\n",
    "}"
   ],
   "id": "cc969402-2946-44e9-91a6-9e3795049852"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve this, a labtech lab can be provided with a *context* that is\n",
    "made available to all tasks. In the following code, we:\n",
    "\n",
    "1.  Pass a `context` to the `labtech.Lab()` constructor, with a\n",
    "    `'DATASETS'` key for the set of `DATASETS` defined above.\n",
    "2.  Redefine `ClassifierExperiment` to accept a `dataset_key` parameter\n",
    "    and use it to look up a dataset inside the `'DATASETS'` key of the\n",
    "    context, which is made available by labtech as `self.context`.\n",
    "3.  Alter the task generation and evaluation code to handle multiple\n",
    "    datasets."
   ],
   "id": "53ea0920-da14-4183-b7cd-45e7489e9c46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labtech.task\n",
    "class ClassifierExperiment:\n",
    "    classifier_task: ClassifierTask\n",
    "    dataset_key: str\n",
    "\n",
    "    def run(self):\n",
    "        dataset = self.context['DATASETS'][self.dataset_key]\n",
    "        X, y = dataset['X'], dataset['y']\n",
    "\n",
    "        clf = clone(self.classifier_task.result)\n",
    "        clf.fit(X, y)\n",
    "        prob_y = clf.predict_proba(X)\n",
    "        return prob_y\n",
    "\n",
    "\n",
    "classifier_experiments = [\n",
    "    ClassifierExperiment(\n",
    "        classifier_task=classifier_task,\n",
    "        dataset_key=dataset_key,\n",
    "    )\n",
    "    # By including multiple for clauses, we will produce a ClassifierExperiment\n",
    "    # for every combination of dataset_key and classifier_task\n",
    "    for dataset_key in DATASETS.keys()\n",
    "    for classifier_task in [LRClassifierTask(), *rf_classifier_tasks]\n",
    "]\n",
    "\n",
    "lab = labtech.Lab(\n",
    "    storage='storage/tutorial/classification_lab_4',\n",
    "    context={\n",
    "        'DATASETS': DATASETS,\n",
    "    },\n",
    ")\n",
    "\n",
    "results = lab.run_tasks(classifier_experiments)\n",
    "for experiment, prob_y in results.items():\n",
    "    dataset_y = DATASETS[experiment.dataset_key][\"y\"]\n",
    "    print(f'{experiment}: {log_loss(dataset_y, prob_y) = :.3}')"
   ],
   "id": "67d7b7da-d0fd-4531-a92a-c32938534917"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lab context can also be useful for passing parameters to a task that\n",
    "won’t affect its result and therefore don’t need to be part of the\n",
    "task’s formal parameters. For example: log levels and task-internal\n",
    "parallelism settings.\n",
    "\n",
    "**It is important that you do NOT make changes to context values that\n",
    "impact task results after you have started caching experiment\n",
    "results** - otherwise your cached results may not reflect your latest\n",
    "context values.\n",
    "\n",
    "### Bringing it all together and aggregating results\n",
    "\n",
    "The following code brings all the steps from this tutorial together in\n",
    "one place, with some additional improvements:\n",
    "\n",
    "-   The “experiment-like” `ClassifierExperiment` and\n",
    "    `MinMaxProbabilityExperiment` task types are now identified by a\n",
    "    common `ExperimentTask` Protocol (which requires each of those\n",
    "    classes to provide a `dataset_key` attribute or property that is\n",
    "    used by the new `ExperimentEvaluationTask`).\n",
    "-   A new, final, `ExperimentEvaluationTask` task that depends on all\n",
    "    `ExperimentTask` tasks is used to compute the loss metric for all\n",
    "    experiments.\n",
    "    -   A final task like this is useful once we have a large number of\n",
    "        experiments as it allows us to cache the final evaluation of all\n",
    "        tasks, meaning that we only need to load experiment results and\n",
    "        re-calculate metrics when experiment parameters have changed or\n",
    "        new experiments have been added.\n",
    "-   We enable labtech’s integration with [`mlflow`](https://mlflow.org/)\n",
    "    by the following additions (see [How can I use labtech with\n",
    "    mlfow?](https://ben-denham.github.io/labtech/cookbook/#how-can-i-use-labtech-with-mlflow)\n",
    "    for details):\n",
    "    1.  We add `mlflow_run=True` to the `@labtech.task` decorator of\n",
    "        `ClassifierExperiment` and `MinMaxProbabilityExperiment`,\n",
    "        indicating that each task of these types should be recorded as a\n",
    "        “run” in mflow.\n",
    "    2.  We name the over-arching mlflow “experiment” with\n",
    "        `mlflow.set_experiment('example_labtech_experiment')` before the\n",
    "        tasks are run."
   ],
   "id": "5f2ac85d-dde6-4c82-8084-1148380fca17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol\n",
    "\n",
    "import labtech\n",
    "from sklearn.base import clone, ClassifierMixin\n",
    "\n",
    "\n",
    "# === Prepare Datasets ===\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "digits_X, digits_y = datasets.load_digits(return_X_y=True)\n",
    "digits_X = StandardScaler().fit_transform(digits_X)\n",
    "\n",
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "iris_X = StandardScaler().fit_transform(iris_X)\n",
    "\n",
    "DATASETS = {\n",
    "    'digits': {'X': digits_X, 'y': digits_y},\n",
    "    'iris': {'X': iris_X, 'y': iris_y},\n",
    "}\n",
    "\n",
    "\n",
    "# === Classifier Tasks ===\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "class ClassifierTask(Protocol):\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        pass\n",
    "\n",
    "\n",
    "@labtech.task(cache=None)\n",
    "class RFClassifierTask:\n",
    "    n_estimators: int\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        return RandomForestClassifier(\n",
    "            n_estimators=self.n_estimators,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "\n",
    "@labtech.task(cache=None)\n",
    "class LRClassifierTask:\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        return LogisticRegression(\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "\n",
    "# === Experiment Tasks ===\n",
    "\n",
    "class ExperimentTask(Protocol):\n",
    "    dataset_key: str\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        pass\n",
    "\n",
    "\n",
    "@labtech.task(mlflow_run=True)\n",
    "class ClassifierExperiment(ExperimentTask):\n",
    "    classifier_task: ClassifierTask\n",
    "    dataset_key: str\n",
    "\n",
    "    def run(self) -> np.ndarray:\n",
    "        dataset = self.context['DATASETS'][self.dataset_key]\n",
    "        X, y = dataset['X'], dataset['y']\n",
    "\n",
    "        clf = clone(self.classifier_task.result)\n",
    "        clf.fit(X, y)\n",
    "        prob_y = clf.predict_proba(X)\n",
    "        return prob_y\n",
    "\n",
    "\n",
    "@labtech.task(mlflow_run=True)\n",
    "class MinMaxProbabilityExperiment(ExperimentTask):\n",
    "    experiment: ExperimentTask\n",
    "\n",
    "    @property\n",
    "    def dataset_key(self):\n",
    "        return self.experiment.dataset_key\n",
    "\n",
    "    def run(self) -> np.ndarray:\n",
    "        prob_y = self.experiment.result\n",
    "        # Replace the maximum probability in each row with 1,\n",
    "        # and replace all other probabilities with 0.\n",
    "        min_max_prob_y = np.zeros(prob_y.shape)\n",
    "        min_max_prob_y[np.arange(len(prob_y)), prob_y.argmax(axis=1)] = 1\n",
    "        return min_max_prob_y\n",
    "\n",
    "\n",
    "# === Results Aggregation ===\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "@labtech.task\n",
    "class ExperimentEvaluationTask:\n",
    "    experiments: list[ExperimentTask]\n",
    "\n",
    "    def run(self):\n",
    "        return {\n",
    "            experiment: {'log_loss': log_loss(\n",
    "                self.context['DATASETS'][experiment.dataset_key]['y'],\n",
    "                experiment.result,\n",
    "            )}\n",
    "            for experiment in self.experiments\n",
    "        }\n",
    "\n",
    "\n",
    "# === Task Construction ===\n",
    "\n",
    "rf_classifier_tasks = [\n",
    "    RFClassifierTask(\n",
    "        n_estimators=n_estimators,\n",
    "    )\n",
    "    for n_estimators in range(1, 11)\n",
    "]\n",
    "\n",
    "classifier_experiments = [\n",
    "    ClassifierExperiment(\n",
    "        classifier_task=classifier_task,\n",
    "        dataset_key=dataset_key,\n",
    "    )\n",
    "    for dataset_key in DATASETS.keys()\n",
    "    for classifier_task in [LRClassifierTask(), *rf_classifier_tasks]\n",
    "]\n",
    "\n",
    "min_max_prob_experiments = [\n",
    "    MinMaxProbabilityExperiment(\n",
    "        experiment=classifier_experiment,\n",
    "    )\n",
    "    for classifier_experiment in classifier_experiments\n",
    "]\n",
    "\n",
    "evaluation_task = ExperimentEvaluationTask(\n",
    "    experiments=[\n",
    "        *classifier_experiments,\n",
    "        *min_max_prob_experiments,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# === Task Execution ===\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment('example_labtech_experiment')\n",
    "lab = labtech.Lab(\n",
    "    storage='storage/tutorial/classification_lab_final',\n",
    "    context={\n",
    "        'DATASETS': DATASETS,\n",
    "    },\n",
    ")\n",
    "\n",
    "evaluation_result = lab.run_task(evaluation_task)\n",
    "for experiment, result in evaluation_result.items():\n",
    "    print(f'{experiment}: log_loss = {result[\"log_loss\"]:.3}')"
   ],
   "id": "e6815870-38e7-4f3f-873b-56702f3583dc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising tasks and dependencies\n",
    "\n",
    "Finally, we can use Labtech to generate a diagram of a list of tasks\n",
    "that shows all of the task types, parameters, and dependencies:"
   ],
   "id": "e592f1e7-0bd8-4229-93c3-db188104d35b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labtech.diagram import display_task_diagram\n",
    "\n",
    "display_task_diagram([\n",
    "    evaluation_task,\n",
    "], direction='BT')"
   ],
   "id": "2379d6a4-55ed-4a8f-84a3-41a930309cdb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` mermaid\n",
    "classDiagram\n",
    "    direction BT\n",
    "\n",
    "    class ExperimentEvaluationTask\n",
    "    ExperimentEvaluationTask : list[ExperimentTask] experiments\n",
    "    ExperimentEvaluationTask : run()\n",
    "\n",
    "    class ClassifierExperiment\n",
    "    ClassifierExperiment : ClassifierTask classifier_task\n",
    "    ClassifierExperiment : str dataset_key\n",
    "    ClassifierExperiment : run() ndarray\n",
    "\n",
    "    class MinMaxProbabilityExperiment\n",
    "    MinMaxProbabilityExperiment : ExperimentTask experiment\n",
    "    MinMaxProbabilityExperiment : run() ndarray\n",
    "\n",
    "    class LRClassifierTask\n",
    "    LRClassifierTask : run() ClassifierMixin\n",
    "\n",
    "    class RFClassifierTask\n",
    "    RFClassifierTask : int n_estimators\n",
    "    RFClassifierTask : run() ClassifierMixin\n",
    "\n",
    "\n",
    "    ExperimentEvaluationTask <-- \"many\" ClassifierExperiment: experiments\n",
    "    ExperimentEvaluationTask <-- \"many\" MinMaxProbabilityExperiment: experiments\n",
    "\n",
    "    ClassifierExperiment <-- LRClassifierTask: classifier_task\n",
    "    ClassifierExperiment <-- RFClassifierTask: classifier_task\n",
    "\n",
    "    MinMaxProbabilityExperiment <-- ClassifierExperiment: experiment\n",
    "```\n",
    "\n",
    "Such diagrams can help you visualise how your experiments are running,\n",
    "and may be useful to include in project documentation.\n",
    "\n",
    "### Next steps\n",
    "\n",
    "Congratulations on completing the labtech tutorial! You’re now ready to\n",
    "manage complex experiment workflows with ease!\n",
    "\n",
    "To learn more about labtech, you can dive into the following resources:\n",
    "\n",
    "-   [Cookbook of common\n",
    "    patterns](https://ben-denham.github.io/labtech/cookbook) ([as an\n",
    "    interactive\n",
    "    notebook](https://mybinder.org/v2/gh/ben-denham/labtech/main?filepath=examples/cookbook.ipynb))\n",
    "-   [API reference for Labs and\n",
    "    Tasks](https://ben-denham.github.io/labtech/core)\n",
    "-   [More options for cache formats and storage\n",
    "    providers](https://ben-denham.github.io/labtech/caching)\n",
    "-   [Diagramming tools](https://ben-denham.github.io/labtech/diagram)\n",
    "-   [More\n",
    "    examples](https://github.com/ben-denham/labtech/tree/main/examples)"
   ],
   "id": "0a8ea6e2-9fc1-44c6-82cc-7cdc3b6f1447"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
