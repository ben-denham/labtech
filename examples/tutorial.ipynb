{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labtech Tutorial\n",
    "\n",
    "The following tutorial presents a full example of using labtech to\n",
    "easily add parallelism and caching to machine learning experiments.\n",
    "\n",
    "You can also run this tutorial as an ([interactive\n",
    "notebook](https://mybinder.org/v2/gh/ben-denham/labtech/main?filepath=examples/tutorial.ipynb)).\n",
    "\n",
    "Firstly, we will install and import `labtech` along with some other\n",
    "dependencies we will use in this tutorial:"
   ],
   "id": "6f6aeec5-d1ff-45b3-bbdc-03869cfc5f8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install labtech mlflow scikit-learn"
   ],
   "id": "dca45857-b7b9-41a3-8e0d-0b98dc1ae18f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running tasks in parallel\n",
    "\n",
    "TODO"
   ],
   "id": "1e0f8da2-d222-4144-9e7a-8e4abee172f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "digits_X, digits_y = datasets.load_digits(return_X_y=True)\n",
    "digits_X = StandardScaler().fit_transform(digits_X)\n",
    "\n",
    "clf = LogisticRegression(random_state=1)\n",
    "clf.fit(digits_X, digits_y)\n",
    "# Note: Normally we would want to test predictions on a separate test set,\n",
    "# but we will work with a training set only for simplicity in this tutorial.\n",
    "prob_y = clf.predict_proba(digits_X)\n",
    "\n",
    "print(log_loss(digits_y, prob_y))"
   ],
   "id": "a81c9777-bda8-42b1-87ef-4c652db11ed3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ],
   "id": "eac691c2-06f9-424a-9416-ac5c0375e657"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labtech\n",
    "\n",
    "@labtech.task\n",
    "class ClassifierExperiment:\n",
    "    random_state: int\n",
    "\n",
    "    def run(self):\n",
    "        clf = LogisticRegression(random_state=self.random_state)\n",
    "        clf.fit(digits_X, digits_y)\n",
    "        return clf.predict_proba(digits_X)\n",
    "\n",
    "\n",
    "classifier_experiments = [\n",
    "    ClassifierExperiment(\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    for random_state in range(10)\n",
    "]"
   ],
   "id": "085276cb-af36-4754-98c3-dc9f133c164d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ],
   "id": "3c7a97af-0e91-48e3-bf28-ba2c5a730884"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = labtech.Lab(\n",
    "    storage='classification_lab_1',\n",
    "    notebook=True,\n",
    ")\n",
    "\n",
    "results = lab.run_tasks(classifier_experiments)\n",
    "print({\n",
    "    experiment: log_loss(digits_y, prob_y)\n",
    "    for experiment, prob_y in results.items()\n",
    "})"
   ],
   "id": "491af7dc-256b-4263-b175-75b5c343fd90"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependent tasks: concurrency and re-using cached results\n",
    "\n",
    "TODO"
   ],
   "id": "8aaddf8b-8243-4032-ba85-af28afca04c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.run_tasks(classifier_experiments)"
   ],
   "id": "3787ad8f-ce7c-4059-a68b-39629ec6dbf2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    lab.cached_tasks([ClassifierExperiment])\n",
    "\n",
    "TODO"
   ],
   "id": "9f91401a-7ecb-45f1-8c76-48659fa6642a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labtech.task\n",
    "class MinMaxProbabilityExperiment:\n",
    "    classifier_experiment: ClassifierExperiment\n",
    "\n",
    "    def run(self):\n",
    "        prob_y = self.classifier_experiment.result\n",
    "        # Replace the maximum probability in each row with 1,\n",
    "        # and replace all other probabilities with 0.\n",
    "        min_max_prob_y = np.zeros(prob_y.shape)\n",
    "        min_max_prob_y[np.arange(len(prob_y), prob_y.argmax(axis=1)] = 1\n",
    "        return min_max_prob_y"
   ],
   "id": "04ab65d4-ce96-4494-85f7-fa54d13848e9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ],
   "id": "d7f455c2-523b-476d-8797-7f591a1c4d5b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_prob_experiments = [\n",
    "    MinMaxProbabilityExperiment(\n",
    "        classifier_experiment=classifier_experiment,\n",
    "    )\n",
    "    for classifier_experiment in classifier_experiments\n",
    "]\n",
    "\n",
    "results = lab.run_tasks(min_max_prob_experiments)\n",
    "print({\n",
    "    experiment: log_loss(digits_y, prob_y)\n",
    "    for experiment, prob_y in results.items()\n",
    "})"
   ],
   "id": "22c4da7d-1097-49d2-ae68-ecf109066547"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterising tasks with complex objects\n",
    "\n",
    "TODO"
   ],
   "id": "a7c72a8c-175b-453d-adf7-88eed1415f1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol\n",
    "\n",
    "from sklearn.base import clone, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "class ClassifierTask(Protocol):\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Constructing a classifier object is inexpensive, so we don't need to\n",
    "# cache the result\n",
    "@labtech.task(cache=None)\n",
    "class LRClassifierTask:\n",
    "    random_state: int\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        return LogisticRegression(\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "\n",
    "\n",
    "@labtech.task(cache=None)\n",
    "class NBClassifierTask:\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        return GaussianNB()\n",
    "\n",
    "\n",
    "@labtech.task\n",
    "class ClassifierExperiment:\n",
    "    classifier_task: ClassifierTask\n",
    "\n",
    "    def run(self):\n",
    "        clf = clone(self.classifier_task.result)\n",
    "        clf.fit(digits_X, digits_y)\n",
    "        probs = clf.predict_proba(digits_X)\n",
    "        return probs"
   ],
   "id": "372bd7e6-c837-4622-aa7a-2f95322998be"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ],
   "id": "2d486a8f-a746-47fe-984c-c435555c9f03"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier_tasks = [\n",
    "    LRClassifierTask(\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    for random_state in range(10)\n",
    "]\n",
    "classifier_experiments = [\n",
    "    ClassifierExperiment(\n",
    "        classifier_task=classifier_task,\n",
    "    )\n",
    "    for classifier_task in [\n",
    "        NBClassifierTask(),\n",
    "        *lr_classifier_tasks,\n",
    "    ]\n",
    "]\n",
    "\n",
    "lab = labtech.Lab(\n",
    "    storage='classification_lab_2',\n",
    "    notebook=True,\n",
    ")\n",
    "\n",
    "results = lab.run_tasks(classifier_experiments)\n",
    "print({\n",
    "    experiment: log_loss(digits_y, prob_y)\n",
    "    for experiment, prob_y in results.items()\n",
    "})"
   ],
   "id": "4e04f8a7-5c02-43f9-b589-385bb7c86a1a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "### Providing large objects as context"
   ],
   "id": "f8ef4e2b-b179-45ff-9d5b-2df87396a217"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "iris_X = StandardScaler().fit_transform(iris_X)\n",
    "\n",
    "DATASETS = {\n",
    "    'digits': {'X': digits_X, 'y': digits_y},\n",
    "    'iris': {'X': iris_X, 'y': iris_y},\n",
    "}\n",
    "\n",
    "\n",
    "@labtech.task\n",
    "class ClassifierExperiment:\n",
    "    classifier_task: ClassifierTask\n",
    "    dataset_key: str\n",
    "\n",
    "    def run(self):\n",
    "        dataset = self.context['DATASETS'][self.dataset_key]\n",
    "        X, y = dataset['X'], dataset['y']\n",
    "\n",
    "        clf = clone(self.classifier_task.result)\n",
    "        clf.fit(X, y)\n",
    "        return clf.predict_proba(X)"
   ],
   "id": "cd5b5243-7a71-4f61-9eac-e94d590fe9d9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ],
   "id": "d6db51e7-86ff-4316-a98d-e6e5b90daa27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_experiments = [\n",
    "    ClassifierExperiment(\n",
    "        classifier_task=classifier_task,\n",
    "        dataset_key=dataset_key,\n",
    "    )\n",
    "    # By including multiple for clauses, we will produce a ClassifierExperiment\n",
    "    # for every combination of dataset_key and classifier_task\n",
    "    for dataset_key in datasets.keys()\n",
    "    for classifier_task in [NBClassifierTask(), *lr_classifier_tasks]\n",
    "]\n",
    "\n",
    "lab = labtech.Lab(\n",
    "    storage='classification_lab_3',\n",
    "    notebook=True,\n",
    "    context={\n",
    "        'DATASETS': DATASETS,\n",
    "    },\n",
    ")\n",
    "\n",
    "results = lab.run_tasks(classifier_experiments)\n",
    "print({\n",
    "    experiment: log_loss(digits_y, prob_y)\n",
    "    for experiment, prob_y in results.items()\n",
    "})"
   ],
   "id": "fc5fbd58-88c3-4168-abf2-36c2b6ef85db"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it all together and aggregating results\n",
    "\n",
    "TODO"
   ],
   "id": "f7fe0695-d953-44f6-99a1-2ab4a911e3e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Protocol\n",
    "\n",
    "import labtech\n",
    "from sklearn.base import clone, ClassifierMixin\n",
    "\n",
    "\n",
    "# === Prepare Datasets ===\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "digits_X, digits_y = datasets.load_digits(return_X_y=True)\n",
    "digits_X = StandardScaler().fit_transform(digits_X)\n",
    "\n",
    "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
    "iris_X = StandardScaler().fit_transform(iris_X)\n",
    "\n",
    "DATASETS = {\n",
    "    'digits': {'X': digits_X, 'y': digits_y},\n",
    "    'iris': {'X': iris_X, 'y': iris_y},\n",
    "}\n",
    "\n",
    "\n",
    "# === Classifier Tasks ===\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "class ClassifierTask(Protocol):\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Constructing a classifier object is inexpensive, so we don't need to\n",
    "# cache the result\n",
    "@labtech.task(cache=None)\n",
    "class LRClassifierTask:\n",
    "    random_state: int\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        return LogisticRegression(\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "\n",
    "\n",
    "@labtech.task(cache=None)\n",
    "class NBClassifierTask:\n",
    "\n",
    "    def run(self) -> ClassifierMixin:\n",
    "        return GaussianNB()\n",
    "\n",
    "\n",
    "# === Experiment Tasks ===\n",
    "\n",
    "class ExperimentTask(Protocol):\n",
    "\n",
    "    def run(self) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "\n",
    "@labtech.task(mlflow_run=True)\n",
    "class ClassifierExperiment:\n",
    "    classifier_task: ClassifierTask\n",
    "    dataset_key: str\n",
    "\n",
    "    def run(self) -> np.ndarray:\n",
    "        dataset = self.context['DATASETS'][self.dataset_key]\n",
    "        X, y = dataset['X'], dataset['y']\n",
    "\n",
    "        clf = clone(self.classifier_task.result)\n",
    "        clf.fit(X, y)\n",
    "        return clf.predict_proba(X)\n",
    "\n",
    "\n",
    "@labtech.task(mlflow_run=True)\n",
    "class MinMaxProbabilityExperiment:\n",
    "    experiment: ExperimentTask\n",
    "\n",
    "    def run(self) -> np.ndarray:\n",
    "        prob_y = self.experiment.result\n",
    "        # Replace the maximum probability in each row with 1,\n",
    "        # and replace all other probabilities with 0.\n",
    "        min_max_prob_y = np.zeros(prob_y.shape)\n",
    "        min_max_prob_y[np.arange(len(prob_y), prob_y.argmax(axis=1)] = 1\n",
    "        return min_max_prob_y\n",
    "\n",
    "\n",
    "# === Results Aggregation ===\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "@labtech.task\n",
    "class ExperimentEvaluationTask:\n",
    "    experiments: list[ExperimentTask]\n",
    "\n",
    "    def run(self):\n",
    "        return {\n",
    "            experiment: log_loss(digits_y, experiment.result)\n",
    "            for experiment in self.experiments\n",
    "        }\n",
    "\n",
    "\n",
    "# === Task Construction ===\n",
    "\n",
    "lr_classifier_tasks = [\n",
    "    LRClassifierTask(\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    for random_state in range(10)\n",
    "]\n",
    "\n",
    "classifier_experiments = [\n",
    "    ClassifierExperiment(\n",
    "        classifier_task=classifier_task,\n",
    "        dataset_key=dataset_key,\n",
    "    )\n",
    "    for dataset_key in datasets.keys()\n",
    "    for classifier_task in [NBClassifierTask(), *lr_classifier_tasks]\n",
    "]\n",
    "\n",
    "min_max_prob_experiments = [\n",
    "    MinMaxProbabilityExperiment(\n",
    "        classifier_experiment=classifier_experiment,\n",
    "    )\n",
    "    for classifier_experiment in classifier_experiments\n",
    "]\n",
    "\n",
    "evaluation_task = ExperimentEvaluationTask(\n",
    "    experiments=[\n",
    "        *classifier_experiments,\n",
    "        *min_max_prob_experiments,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# === Task Execution ===\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment('example_labtech_experiment')\n",
    "lab = labtech.Lab(\n",
    "    storage='classification_lab_final',\n",
    "    notebook=True,\n",
    "    context={\n",
    "        'DATASETS': DATASETS,\n",
    "    },\n",
    ")\n",
    "\n",
    "evaluation_result = lab.run_task(evaluation_task)\n",
    "print(evaluation_result)"
   ],
   "id": "557ac634-a052-4ef5-933f-bea2ff9fe16a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "TODO"
   ],
   "id": "bfebaef7-161d-46c6-a9fd-4912e66094d1"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
